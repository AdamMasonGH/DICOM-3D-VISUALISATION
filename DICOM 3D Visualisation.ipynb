{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from math import *\n",
    "from functools import reduce\n",
    "from PIL import Image as Img\n",
    "from PIL import ImageTk\n",
    "from PIL import ImageEnhance\n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a14403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in dicom files\n",
    "import pydicom as dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skimage image processing packages\n",
    "import skimage\n",
    "from skimage import measure, morphology\n",
    "from skimage.morphology import ball, binary_closing\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy linear algebra functions \n",
    "from scipy.linalg import norm\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db89742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipywidgets for some interactive plots\n",
    "from ipywidgets.widgets import * \n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly 3D interactive graphs \n",
    "import plotly\n",
    "from plotly.graph_objs import *\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "import chart_studio.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ada7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path and load files \n",
    "#path = r'C:\\Users\\adamj\\OneDrive\\Desktop\\DICOM Python\\Dicom Files'\n",
    "#output_path = r'C:\\Users\\adamj\\OneDrive\\Desktop\\DICOM Python\\Numpy Data'\n",
    "path = '/Users/adamj/OneDrive/Desktop/DICOM Python/Dicom Files/'\n",
    "output_path = working_path = '/Users/adamj/OneDrive/Desktop/DICOM Python/Numpy Data/'\n",
    "g = glob(path + '/*.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9fdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking we're in the correct path\n",
    "print (\"Total of %d DICOM images.\\nFirst 5 filenames:\" % len(g))\n",
    "print ('\\n'.join(g[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785036de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hengloose.medium.com/a-comprehensive-starter-guide-to-visualizing-and-analyzing-dicom-images-in-python-7a8430fcb7ed\n",
    "# https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "# Load all DICOM images from a folder into a list for manipulation\n",
    "\n",
    "def load_scan(path):\n",
    "    ct_images = os.listdir(path)\n",
    "    slices = [dicom.dcmread(path + '/' + s) for s in ct_images]\n",
    "    slices = [s for s in slices if 'SliceLocation' in s]\n",
    "    slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hengloose.medium.com/a-comprehensive-starter-guide-to-visualizing-and-analyzing-dicom-images-in-python-7a8430fcb7ed\n",
    "# https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "# Converts all raw voxel values into Houndsfeld Units. \n",
    "# HU's are useful because it is standardized across all CT scans regardless \n",
    "# of the absolute number of photons the scanner detector captured.\n",
    "\n",
    "def get_pixels_hu(scans):\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfeld units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "   \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = load_scan(path)\n",
    "patient_pixels = get_pixels_hu(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bbe4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, depth = patient_pixels.shape\n",
    "print(f'The image object has the following dimensions:\\nheight={height}\\nwidth={width}\\ndepth={depth}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5363fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "np.save(output_path + \"fullimages_%d.npy\" % (id), patient_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92235b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_axes(): # gets rid of x and y axes on plots if desired\n",
    "    ax = plt.gca()\n",
    "    plt.axis('off')\n",
    "    #ax.get_xaxis().set_visible(False)\n",
    "    #ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c53f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want to check whether the Houndsfeld Units are properly scaled and represented\n",
    "file_used=output_path+\"fullimages_%d.npy\" % id\n",
    "imgs_to_process = np.load(file_used).astype(np.float64)\n",
    "\n",
    "plt.hist(imgs_to_process.flatten(), bins=50, color='c')\n",
    "plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Houndsfeld Units of various substances in the human body, for reference.\n",
    "HU_table = Img.open(\"Houndsfeld Units Table.jpg\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(HU_table)\n",
    "hide_axes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99519bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical Analysis of Histogram\n",
    "# High volume of air\n",
    "# Fat, Water, Blood, Muscle and Liver may be present, but difficult to determine the quantity of each\n",
    "# Small bits of bone are present (mainly cancellous bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b4ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will skip every 4 slices to produce an image stack to see what we are looking at.\n",
    "# https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "id = 0\n",
    "imgs_to_process = np.load(output_path+'fullimages_{}.npy'.format(id))\n",
    "\n",
    "def sample_stack(stack, rows=7, cols=7, start_with=1, show_every=5):\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n",
    "    for i in range(rows*cols):\n",
    "        ind = start_with + i*show_every\n",
    "        ax[int(i/rows),int(i % rows)].set_title('slice %d' % ind)\n",
    "        ax[int(i/rows),int(i % rows)].imshow(stack[ind],cmap='gray')\n",
    "        ax[int(i/rows),int(i % rows)].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_stack(imgs_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Slice Thickness: %f\" % patient[0].SliceThickness)\n",
    "print(\"Pixel Spacing (row, col): (%f, %f) \" % (patient[0].PixelSpacing[0], patient[0].PixelSpacing[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This means each slice is 1.5 mm thick and each voxel represents approximately 0.7 mm. A CT slice is typically\n",
    "reconstructed at 512x512 voxels, which means each slice represents approximately 379 mm of data in length and width.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142526b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the image in 3D isometric form.\n",
    "\"\"\"Using the metadata from the DICOM Files we can determine the size of each voxel as the slice thickness. To be able\n",
    "to display a 3D isometric image, we need to resample each slice into 1x1x1 mm pixels and slices\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35915c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "\n",
    "id = 0\n",
    "imgs_to_process = np.load(output_path+'fullimages_{}.npy'.format(id))\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = map(float, ([scan[0].SliceThickness, scan[0].PixelSpacing[0], scan[0].PixelSpacing[1]]))\n",
    "    spacing = np.array(list(spacing))\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor)\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "print(\"Shape before resampling\\t\", imgs_to_process.shape)\n",
    "imgs_after_resamp, spacing = resample(imgs_to_process, patient, [1,1,1])\n",
    "print(\"Shape after resampling\\t\", imgs_after_resamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50546419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "\n",
    "def make_mesh(image, threshold=-300, step_size=1):\n",
    "\n",
    "    print(\"Transposing surface\")\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    print(\"Calculating surface\")\n",
    "    verts, faces, norm, val = measure.marching_cubes(p, threshold, step_size=step_size, allow_degenerate=True) \n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(verts, faces):\n",
    "    print(\"Drawing\")\n",
    "    x,y,z = zip(*verts) \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], linewidths=0.05, alpha=0.1)\n",
    "    face_color = [0.5, 0.5, 1] # sets the colour of the image (RGB Format)\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, max(x))\n",
    "    ax.set_ylim(0, max(y))\n",
    "    ax.set_zlim(0, max(z))\n",
    "    ax.set_facecolor((0.5, 0.5, 0.5))\n",
    "    plt.show()\n",
    "    \n",
    "vert, face = make_mesh(imgs_after_resamp, 350)\n",
    "plot_3d(vert, face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_3d(verts, faces): # interactive 3D visualisation\n",
    "    x,y,z = zip(*verts) \n",
    "    \n",
    "    print(\"Drawing\")\n",
    "    \n",
    "    # Make the colormap single color since the axes are positional not intensity. \n",
    "    #    colormap=['rgb(255,105,180)','rgb(255,255,51)','rgb(0,191,255)']\n",
    "    colormap=['rgb(227,219,201)','rgb(227,219,201)']  #rgb(227,219,201) rgb(236, 236, 212)\n",
    "    \n",
    "    fig = FF.create_trisurf(x=x,\n",
    "                        y=y, \n",
    "                        z=z, \n",
    "                        plot_edges=False,\n",
    "                        colormap=colormap,\n",
    "                        simplices=faces,\n",
    "                        backgroundcolor='rgb(64, 64, 64)',\n",
    "                        title=\"Interactive Visualization\")\n",
    "    iplot(fig)\n",
    "    \n",
    "vert, face = make_mesh(imgs_after_resamp, 350, 2)\n",
    "plotly_3d(vert, face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation - Applying mask\n",
    "# code from: https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "# The below code will:\n",
    "\n",
    "# Standardize the pixel value by subtracting the mean and dividing by the standard deviation\n",
    "# Identify the proper threshold by creating 2 KMeans clusters comparing centered on soft tissue/bone vs lung/air.\n",
    "# Using Erosion) and Dilation) which has the net effect of removing tiny features like pulmonary vessels or noise\n",
    "# Identify each distinct region as separate image labels (think the magic wand in Photoshop)\n",
    "# Using bounding boxes for each image label to identify which ones represent lung and which ones represent \"every thing else\"\n",
    "# Create the masks for lung fields.\n",
    "# Apply mask onto the original image to erase voxels outside of the lung fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(img, display=False):\n",
    "    row_size = img.shape[0]\n",
    "    col_size = img.shape[1]\n",
    "    \n",
    "    # Standardise the pixel values\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = img-mean\n",
    "    img = img/std\n",
    "    # Find the average pixel value near the lungs\n",
    "    # to renormalize washed out images\n",
    "    middle = img[int(col_size/5):int(col_size/5*4),int(row_size/5):int(row_size/5*4)] \n",
    "    mean = np.mean(middle)  \n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    # To improve threshold finding, I'm moving the \n",
    "    # underflow and overflow on the pixel spectrum\n",
    "    img[img==max]=mean\n",
    "    img[img==min]=mean\n",
    "    #\n",
    "    # Using Kmeans to separate foreground (soft tissue / bone) and background (lung/air)\n",
    "    #\n",
    "    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n",
    "    centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "    threshold = np.mean(centers)\n",
    "    thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n",
    "\n",
    "    # First erode away the finer elements, then dilate to include some of the pixels surrounding the lung.  \n",
    "    # We don't want to accidentally clip the lung.\n",
    "\n",
    "    eroded = morphology.erosion(thresh_img,np.ones([3,3]))\n",
    "    dilation = morphology.dilation(eroded,np.ones([8,8]))\n",
    "\n",
    "    labels = measure.label(dilation) # Different labels are displayed in different colors\n",
    "    label_vals = np.unique(labels)\n",
    "    regions = measure.regionprops(labels)\n",
    "    good_labels = []\n",
    "    for prop in regions:\n",
    "        B = prop.bbox\n",
    "        if B[2]-B[0]<row_size/10*9 and B[3]-B[1]<col_size/10*9 and B[0]>row_size/5 and B[2]<col_size/5*4:\n",
    "            good_labels.append(prop.label)\n",
    "    mask = np.ndarray([row_size,col_size],dtype=np.int8)\n",
    "    mask[:] = 0\n",
    "\n",
    "    #\n",
    "    #  After just the lungs are left, we do another large dilation\n",
    "    #  in order to fill in and out the lung mask \n",
    "    #\n",
    "    for N in good_labels:\n",
    "        mask = mask + np.where(labels==N,1,0)\n",
    "    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n",
    "\n",
    "    if (display):\n",
    "        fig, ax = plt.subplots(3, 2, figsize=[12, 12])\n",
    "        ax[0, 0].set_title(\"Original\")\n",
    "        ax[0, 0].imshow(img, cmap='gray')\n",
    "        ax[0, 0].axis('off')\n",
    "        \n",
    "        ax[0, 1].set_title(\"Threshold\")\n",
    "        ax[0, 1].imshow(thresh_img, cmap='gray')\n",
    "        ax[0, 1].axis('off')\n",
    "        \n",
    "        ax[1, 0].set_title(\"After Erosion and Dilation\")\n",
    "        ax[1, 0].imshow(dilation, cmap='gray')\n",
    "        ax[1, 0].axis('off')\n",
    "        \n",
    "        ax[1, 1].set_title(\"Color Labels\")\n",
    "        ax[1, 1].imshow(labels)\n",
    "        ax[1, 1].axis('off')\n",
    "        \n",
    "        ax[2, 0].set_title(\"Final Mask\")\n",
    "        ax[2, 0].imshow(mask, cmap='gray')\n",
    "        ax[2, 0].axis('off')\n",
    "        \n",
    "        ax[2, 1].set_title(\"Apply Mask on Original\")\n",
    "        ax[2, 1].imshow(mask*img, cmap='gray')\n",
    "        ax[2, 1].axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "    return mask*img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7801a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = imgs_after_resamp[140]\n",
    "make_mask(img, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lung = []\n",
    "\n",
    "for img in imgs_after_resamp:\n",
    "    masked_lung.append(make_mask(img))\n",
    "\n",
    "sample_stack(masked_lung, show_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3D = []\n",
    "for img in imgs_after_resamp:\n",
    "    mask3D.append(make_mask(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2bf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mask3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vert, face = make_mesh(mask3D, 350, 2)\n",
    "plotly_3d(vert, face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3e755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
